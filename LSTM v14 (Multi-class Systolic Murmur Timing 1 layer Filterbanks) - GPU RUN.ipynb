{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b7a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf2fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31398e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = list(df[\"Patient ID\"])\n",
    "recording_loc = list(df[\"Recording locations:\"])\n",
    "murmur = list(df[\"Murmur\"])\n",
    "murmur_loc = list(df[\"Murmur locations\"])\n",
    "systolic_murmur_timing = list(df[\"Systolic murmur timing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cce530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_loc = [x.split(\"+\") for x in recording_loc]\n",
    "\n",
    "for i in range(len(murmur_loc)):\n",
    "    if murmur_loc[i] is np.nan:\n",
    "        murmur_loc[i] = []\n",
    "    else:\n",
    "        murmur_loc[i] = murmur_loc[i].split(\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a305f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on patient ID: 85119\n",
      "Error on patient ID: 85119\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(patient_id)):\n",
    "    if murmur[i] == \"Absent\":\n",
    "        for recloc in recording_loc[i]:\n",
    "            full_recording = np.loadtxt(\"SSE/\" + str(patient_id[i]) + \"_\" + recloc + \"_features.csv\", delimiter=',')\n",
    "            initial = 0\n",
    "            while (initial+400) <= len(full_recording):\n",
    "                X.append(full_recording[initial:initial+400])\n",
    "                y.append([1, 0, 0, 0, 0])\n",
    "                initial += 200\n",
    "    elif murmur[i] == \"Present\":\n",
    "        for recloc in recording_loc[i]:\n",
    "            if recloc in murmur_loc[i]:\n",
    "                full_recording = np.loadtxt(\"SSE/\" + str(patient_id[i]) + \"_\" + recloc + \"_features.csv\", delimiter=',')\n",
    "                initial = 0\n",
    "                if systolic_murmur_timing[i] == \"Holosystolic\":\n",
    "                    while (initial+400) <= len(full_recording):\n",
    "                        X.append(full_recording[initial:initial+400])\n",
    "                        y.append([0, 1, 0, 0, 0])\n",
    "                        initial += 200\n",
    "                elif systolic_murmur_timing[i] == \"Early-systolic\":\n",
    "                    while (initial+400) <= len(full_recording):\n",
    "                        X.append(full_recording[initial:initial+400])\n",
    "                        y.append([0, 0, 1, 0, 0])\n",
    "                        initial += 200\n",
    "                elif systolic_murmur_timing[i] == \"Mid-systolic\":\n",
    "                    while (initial+400) <= len(full_recording):\n",
    "                        X.append(full_recording[initial:initial+400])\n",
    "                        y.append([0, 0, 0, 1, 0])\n",
    "                        initial += 200\n",
    "                elif systolic_murmur_timing[i] == \"Late-systolic\":\n",
    "                    while (initial+400) <= len(full_recording):\n",
    "                        X.append(full_recording[initial:initial+400])\n",
    "                        y.append([0, 0, 0, 0, 1])\n",
    "                        initial += 200\n",
    "                else:\n",
    "                    print(\"Error on patient ID:\", patient_id[i])\n",
    "            else:\n",
    "                full_recording = np.loadtxt(\"SSE/\" + str(patient_id[i]) + \"_\" + recloc + \"_features.csv\", delimiter=',')\n",
    "                initial = 0\n",
    "                while (initial+400) <= len(full_recording):\n",
    "                    X.append(full_recording[initial:initial+400])\n",
    "                    y.append([1, 0, 0, 0, 0])\n",
    "                    initial += 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ccc0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 400\n",
    "feature_length = 18\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b76ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ed48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = []\n",
    "y_train_final = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] == [1, 0, 0, 0, 0]:\n",
    "        #randnum = random.uniform(0, 1)\n",
    "        randnum = random.random()\n",
    "        if randnum >= 0.66:\n",
    "            X_train_final.append(X_train[i])\n",
    "            y_train_final.append(y_train[i])\n",
    "    else:\n",
    "        X_train_final.append(X_train[i])\n",
    "        y_train_final.append(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a91f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22341 22341\n",
      "9987 9987\n",
      "7447 7447\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_train_final), len(y_train_final))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c5e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_train_final = np.array(X_train_final)\n",
    "y_train_final = np.array(y_train_final)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19e6b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 400)               670400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                12030     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 155       \n",
      "=================================================================\n",
      "Total params: 682,585\n",
      "Trainable params: 682,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape = (400, 18), return_sequences=False))\n",
    "model.add(Dense(30))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7cd33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ad7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1503/3329 [============>.................] - ETA: 1:11 - loss: 1.0389 - accuracy: 0.6201"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_final, y_train_final, epochs=30, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ec4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final_predicts = model.predict(X_test)\n",
    "final_final_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "score_full = model.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "print('Test loss:', score_full[0])\n",
    "print('Accuracy:', score_full[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d10de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d197b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3933959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final_final_predicts)):\n",
    "    if max(final_final_predicts[i]) != final_final_predicts[i][0]:\n",
    "        print(i, final_final_predicts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0665b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predicts = model.predict(X)\n",
    "full_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(full_predicts)):\n",
    "    if max(full_predicts[i]) != full_predicts[i][0]:\n",
    "        print(i, full_predicts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Confusion Matrix and Classification Report\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "# Classification Report\n",
    "model_report = classification_report(np.argmax(full_predicts, axis=1), np.argmax(y, axis=1))\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = confusion_matrix(np.argmax(full_predicts, axis=1), np.argmax(y, axis=1))\n",
    "print(model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6087099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Learn to predict each class against the other\n",
    "\n",
    "\n",
    "n_classes = 5 # number of class\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], final_final_predicts[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), final_final_predicts.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa04f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "\n",
    "# Process of plotting roc-auc curve belonging to all classes.\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(30, 5))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "title = ['No Murmur', \"Holosystolic\", \"Early-systolic\", \"Mid-systolic\", \"Late-systolic\"]\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    if i == 0:\n",
    "        plt.subplot(151)\n",
    "    elif i == 1:\n",
    "        plt.subplot(152)\n",
    "    elif i == 2:\n",
    "        plt.subplot(153)\n",
    "    elif i == 3:\n",
    "        plt.subplot(154)\n",
    "    else:\n",
    "        plt.subplot(155)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title[i])\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(title[i], roc_auc[i]))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70bd9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
